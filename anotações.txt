Como encontrar palavras em uma sequência de 
caracteres dado um Léxico?


-> da frequência relativa das palavras de um corpus podemos inferir a probabilidade dessas palavras na língua. 

-> se multiplicarmos as probabilidades de cada palavra em uma frase, chegamos à probabilidade da frase em um modelo de unigramas. 

-> se somarmos as complexidades, chegamos à complexidade da frase em um modelo de unigramas.


Nesse sentido, 
- quanto mais elementos em uma frase, maior a complexidade dela
- quanto menos frequentes os elementos de uma frase, maior a complexidade dela


Programação dinâmica:

entrada: "issoélegal"
saída: "isso é legal"

 issoélegal
      ^
 issoél : n
  ssoél : n
   soél : n
    oél : n
     él : n
      l : n

  [i ,s ,s ,isso,é , l  ,e   ,g   ,a   ,legal]
[0,12,30,48,9   ,16,1016,1020,2020,2024,36   ]
  [legal, é, isso]
  [isso, é, legal]
  "isso é legal"


aminhafrase
^
a

aminhafrase
 ^
am
 a

aminhafrase
    ^
aminh
 minh
  inh
   nh
    h


Algoritmo do Chunker:


# Léxico contendo a complexidade de cada caractere do corpus. Novos itens serão adicionados a ele da seguinte forma: 

    1. Unir os itens adjacentes e contar suas ocorrências em um Léxico de candidatos.
    2. Acrescentar os K candidatos mais frequentes ao Léxico oficial.
    3. Analisar o texto utilizando as frequências provisórias. 
    4. Recalcular as frequências dos itens lexicais. 

# Somar: comprimento do léxico + comprimento do corpus
# Verificar diminuição



## Léxico do Chunker
-> As frequências/complexidades dos caracteres
-> Adicione novas palavras a partir do texto (ignorando os caracteres isolados)
-> Meça o tamanho do léxico baseado nas novas palavras. 

-> Léxico de caracteres (imutável)
-> Léxico de palavras (mutável a cada iteração). 

## Junção de pares para alimentar o léxico com novas palavras. 
-> Juntar cada par de palavras do corpus. 
-> pegar a frequência de cada par e eleger X pares para serem adicionados ao léxico
-> esses X pares vão entrar em um léxico de complexidade para reanálise do corpus
-> essa reanálise do corpus gerará um novo Léxico do Chunker. 

## Como funciona a adição de tokens nos léxicos que temos atualmente?





